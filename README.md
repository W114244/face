import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration
import cv2
import mediapipe as mp
import numpy as np
import time
import math
from PIL import Image, ImageDraw, ImageFont

# --- 1. æ ¸å¿ƒè³‡æ–™åº« (æ²¿ç”¨ä½ çš„ 17 å­—é›™è»¸æ¯”ä¾‹) ---
TARGETS = {
    'å¤§': {"h_range": (0.20, 0.40), "w_range": (0.35, 0.55), "hint": "ä¸‹å·´æ”¾é¬†å‚ç›´ä¸‹æ²‰", "muscle": "é¡³è‚Œ (Temporal)"},
    'å—š': {"h_range": (0.05, 0.15), "w_range": (0.15, 0.30), "hint": "é›™å”‡æ¥µåº¦å‘ä¸­å¿ƒç¸®åœ“", "muscle": "å£è¼ªåŒè‚Œ (Orbicularis)"},
    'ä¸€': {"h_range": (0.02, 0.12), "w_range": (0.65, 0.85), "hint": "å˜´è§’ç”¨åŠ›å‘è€³æ ¹æ‹‰å¹³", "muscle": "ç¬‘è‚Œ (Risorius)"},
    'å•Š': {"h_range": (0.35, 0.60), "w_range": (0.40, 0.65), "hint": "å‚ç›´å¼µåŠ›æœ€å¤§åŒ–", "muscle": "é™å£è§’è‚Œ (Depressor)"},
    'å–”': {"h_range": (0.25, 0.45), "w_range": (0.30, 0.50), "hint": "å‘ˆå‚ç›´é•·æ©¢åœ“å½¢", "muscle": "å£è¼ªåŒè‚Œä¸Šå±¤"},
    'å±‹': {"h_range": (0.02, 0.12), "w_range": (0.15, 0.28), "hint": "æœ€ç·Šæ¹Šçš„ç¸®å°åœ“å­”", "muscle": "å£è¼ªåŒè‚Œæ ¸å¿ƒ"},
    'å“¼': {"h_range": (0.00, 0.08), "w_range": (0.45, 0.65), "hint": "é–‰å”‡ç”¨åŠ›æŠ¿ç·Š", "muscle": "é ¦è‚Œ (Mentalis)"},
    'ä¸ƒ': {"h_range": (0.05, 0.15), "w_range": (0.70, 0.95), "hint": "æ©«å‘æ‹‰åŠ›æ¥µé™ï¼Œéœ²ç‰™", "muscle": "ç¬‘è‚Œ+é °è‚Œæ¥µé™"},
    'å’ª': {"h_range": (0.00, 0.08), "w_range": (0.60, 0.85), "hint": "æŠ¿å˜´å»¶å±•ï¼Œæ¸¬è©¦è‚Œè‚‰è€åŠ›", "muscle": "å£è¼ªåŒè‚Œé‚Šç·£"}
}

# --- 2. ä»‹é¢è¨­å®š ---
st.set_page_config(page_title="AI Speech Coach", layout="centered")
st.title("ğŸ—£ï¸ AI èªè¨€æ•™ç·´ (æ‰‹æ©Ÿç‰ˆ)")

# å´é‚Šé¸å–®å–ä»£éµç›¤èˆ‡ Tkinter
sel_word = st.sidebar.selectbox("ğŸ¯ é¸æ“‡ç·´ç¿’å­—", list(TARGETS.keys()))
diff_lv = st.sidebar.slider("ğŸ”¥ é›£åº¦ç­‰ç´š (1-5)", 1, 5, 3)
tol_map = {1: 0.12, 2: 0.08, 3: 0.05, 4: 0.03, 5: 0.01}
TOLERANCE = tol_map[diff_lv]

# --- 3. æ ¸å¿ƒè™•ç†é¡åˆ¥ ---
class FaceProcessor(VideoTransformerBase):
    def __init__(self):
        self.face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)
        self.hold_start = None
        self.count = 0

    def transform(self, frame):
        img = frame.to_ndarray(format="bgr24")
        img = cv2.flip(img, 1)
        h_img, w_img, _ = img.shape
        
        results = self.face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        is_ok = False
        
        if results.multi_face_landmarks:
            for flm in results.multi_face_landmarks:
                lm = flm.landmark
                # è‡‰å¯¬åŸºæº–è¨ˆç®— (ä½ çš„æ­¸ä¸€åŒ–é‚è¼¯)
                f_w = math.sqrt((lm[454].x - lm[234].x)**2 + (lm[454].y - lm[234].y)**2)
                curr_h = abs(lm[13].y - lm[14].y) / f_w
                curr_w = abs(lm[78].x - lm[308].x) / f_w
                
                # åˆ¤å®šé‚è¼¯
                t = TARGETS[sel_word]
                W_TOL = TOLERANCE * (12.0 if diff_lv <= 2 else 6.0 if diff_lv <= 4 else 3.0)
                h_ok = (t["h_range"][0]-TOLERANCE <= curr_h <= t["h_range"][1]+TOLERANCE)
                w_ok = (t["w_range"][0]-W_TOL <= curr_w <= t["w_range"][1]+W_TOL)
                is_ok = h_ok and w_ok

                # ç¹ªè£½ä½ çš„è¦–è¦ºç®­é ­å°å¼•
                tp, bp = (int(lm[13].x*w_img), int(lm[13].y*h_img)), (int(lm[14].x*w_img), int(lm[14].y*h_img))
                lp, rp = (int(lm[78].x*w_img), int(lm[78].y*h_img)), (int(lm[308].x*w_img), int(lm[308].y*h_img))
                
                def draw_arrow(p1, p2, color):
                    cv2.arrowedLine(img, p1, p2, color, 3, tipLength=0.3)

                # å‚ç›´å¼•å° (å¤ªå°å‰‡å¾€å¤–æ‹‰ï¼Œå¤ªå¤§å‰‡å¾€å…§ç¸®)
                if curr_h < t["h_range"][0]-TOLERANCE: 
                    draw_arrow(tp, (tp[0], tp[1]-40), (0, 255, 0))
                    draw_arrow(bp, (bp[0], bp[1]+40), (0, 255, 0))
                elif curr_h > t["h_range"][1]+TOLERANCE:
                    draw_arrow(tp, (tp[0], tp[1]+40), (0, 0, 255))
                    draw_arrow(bp, (bp[0], bp[1]-40), (0, 0, 255))

        # æˆåŠŸè¨ˆæ™‚å™¨
        if is_ok:
            if self.hold_start is None: self.hold_start = time.time()
            if time.time() - self.hold_start >= 2.0:
                self.count += 1
                self.hold_start = None
        else:
            self.hold_start = None

        return img

# --- 4. å•Ÿå‹• Web ä¸²æµ ---
webrtc_streamer(
    key="speech-coach",
    video_transformer_factory=FaceProcessor,
    rtc_configuration=RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}),
    media_stream_constraints={"video": True, "audio": False}
)

# é¡¯ç¤ºå‹•ä½œæŒ‡å¼•
st.info(f"ğŸ’¡ å‹•ä½œæŒ‡å¼•ï¼š{TARGETS[sel_word]['hint']}")
st.warning(f"ğŸ’ª è¨“ç·´è‚Œè‚‰ï¼š{TARGETS[sel_word]['muscle']}")