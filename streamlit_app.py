import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration
import cv2
import mediapipe as mp
import numpy as np
import math

# --- 1. æ ¸å¿ƒè³‡æ–™åº« (å®Œæ•´ 17 å­—) ---
TARGETS = {
    'å¤§': {"h_range": (0.20, 0.40), "hint": "ä¸‹å·´æ”¾é¬†å‚ç›´ä¸‹æ²‰"},
    'å—š': {"h_range": (0.05, 0.15), "hint": "é›™å”‡æ¥µåº¦å‘ä¸­å¿ƒç¸®åœ“"},
    'ä¸€': {"h_range": (0.02, 0.12), "hint": "å˜´è§’ç”¨åŠ›å‘è€³æ ¹æ‹‰å¹³"},
    'å•Š': {"h_range": (0.35, 0.60), "hint": "å‚ç›´å¼µåŠ›æœ€å¤§åŒ–"},
    'å–”': {"h_range": (0.25, 0.45), "hint": "å‘ˆå‚ç›´é•·æ©¢åœ“å½¢"},
    'å±‹': {"h_range": (0.02, 0.12), "hint": "æœ€ç·Šæ¹Šçš„ç¸®å°åœ“å­”"},
    'èª’': {"h_range": (0.12, 0.25), "hint": "å˜´è§’å¾®å¼µä¸¦æ©«å‘æ‹‰é–‹"},
    'ä¸ƒ': {"h_range": (0.05, 0.15), "hint": "æ©«å‘æ‹‰åŠ›æ¥µé™ï¼Œéœ²ç‰™"},
    'å’ª': {"h_range": (0.00, 0.08), "hint": "æŠ¿å˜´å»¶å±•ï¼Œæ¸¬è©¦è‚Œè‚‰è€åŠ›"},
    'å’•': {"h_range": (0.10, 0.20), "hint": "å¾ŒèˆŒæ ¹ç™¼åŠ›ï¼Œå˜´å¾®åœ“"},
    'å’–': {"h_range": (0.30, 0.50), "hint": "èˆŒæ ¹ä¸‹æ²‰ï¼Œå¤§å¼µå£"},
    'å”': {"h_range": (0.05, 0.15), "hint": "ç‰™é½’å¾®åˆï¼Œå˜´è§’æ‹‰é–‹"},
    'è˜‡': {"h_range": (0.08, 0.18), "hint": "å”‡éƒ¨å¾®çªï¼Œå°åœ“å£"},
    'ç‰¹': {"h_range": (0.15, 0.25), "hint": "èˆŒå°–æŠµé½’é½¦ï¼Œç¬é–“å½ˆé–‹"},
    'å‹’': {"h_range": (0.10, 0.20), "hint": "èˆŒå°–å½ˆæ“Šï¼Œå£å‹è‡ªç„¶"},
    'é…': {"h_range": (0.15, 0.30), "hint": "é›™å”‡çˆ†ç™¼åŠ›è¨“ç·´"},
    'ç¾': {"h_range": (0.05, 0.15), "hint": "æŠ¿å˜´å¾Œæ”¾é¬†ï¼Œå”‡è‚Œè¨“ç·´"}
}

st.set_page_config(page_title="AI Speech Coach", layout="centered")
st.title("ğŸ—£ï¸ AI èªè¨€æ•™ç·´ (17å­—å®Œå…¨é«”)")

sel_word = st.sidebar.selectbox("ğŸ¯ ç·´ç¿’ç›®æ¨™", list(TARGETS.keys()))

class FaceProcessor(VideoTransformerBase):
    def __init__(self):
        self.face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)

    def transform(self, frame):
        img = frame.to_ndarray(format="bgr24")
        img = cv2.flip(img, 1) # é¡åƒ
        h_img, w_img, _ = img.shape
        results = self.face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        
        if results.multi_face_landmarks:
            for flm in results.multi_face_landmarks:
                lm = flm.landmark
                # ç¹ªè£½è¿½è¹¤é»å¹«åŠ©å°æº–
                cv2.circle(img, (int(lm[13].x*w_img), int(lm[13].y*h_img)), 3, (0, 255, 0), -1)
                cv2.circle(img, (int(lm[14].x*w_img), int(lm[14].y*h_img)), 3, (0, 255, 0), -1)
        
        # --- è£œä¸Šé€™è¡Œéˆé­‚ return ---
        return img 

webrtc_streamer(
    key="speech-coach-v2", 
    video_transformer_factory=FaceProcessor,
    rtc_configuration=RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}),
    media_stream_constraints={"video": True, "audio": False}
)

st.info(f"ğŸ’¡ ç™¼éŸ³æŒ‡å¼•ï¼š{TARGETS[sel_word]['hint']}")